{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import librosa\n",
    "from librosa.display import specshow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, dct, ifft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "from scipy.special import logsumexp\n",
    "from collections import defaultdict, namedtuple\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from hyperparameters import *\n",
    "\n",
    "# warnings.simplefilter('error')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(sound, sampling_rate=SAMPLE_RATE, shift=32., L=128., mel_coefs=120, mfcc_coefs=12, alpha=0.9, eps=1e-9):\n",
    "    mfcc = librosa.feature.mfcc(y=sound, sr=sampling_rate, n_mfcc=mfcc_coefs)\n",
    "    energy = librosa.feature.rms(sound)\n",
    "    mfcc_energy = np.vstack((mfcc, energy))\n",
    "    dx = librosa.feature.delta(mfcc_energy, order=1, width=3)\n",
    "    d2x = librosa.feature.delta(mfcc_energy, order=2, width=3)\n",
    "    res_features = np.vstack((mfcc_energy, dx, d2x)).T\n",
    "    return res_features.astype(np.float32)\n",
    "\n",
    "\n",
    "def show(audio):\n",
    "    return Audio(audio, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path=DATA_PATH):\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    for uid, user_id in tqdm(enumerate(os.listdir(data_path))):\n",
    "        videos = os.listdir(os.path.join(data_path, user_id))\n",
    "        random.shuffle(videos)\n",
    "        split = round(TRAIN_SPLIT * len(videos))\n",
    "        train_data[uid] = []\n",
    "        test_data[uid] = []\n",
    "        for vid, video_id in enumerate(videos):\n",
    "            for file in os.listdir(os.path.join(data_path, user_id, video_id)):\n",
    "                full_path = os.path.join(data_path, user_id, video_id, file)\n",
    "                record = librosa.load(full_path, sr=SAMPLE_RATE)[0]\n",
    "                for i in range(0, len(record) - NUM_FRAMES + 1, NUM_FRAMES): # last part with len < NUM_FRAMES is skipped\n",
    "                    x = record[i:i+NUM_FRAMES]\n",
    "                    if vid < split:\n",
    "                        train_data[uid].append(extract_mfcc(x))\n",
    "                    else:\n",
    "                        test_data[uid].append(extract_mfcc(x))\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Records(Dataset):\n",
    "    def __init__(self, records, pos=5, neg=5):\n",
    "        self.indices = []\n",
    "        self.target = []\n",
    "        self.data = records\n",
    "        for u, data in records.items():\n",
    "            for i, x in enumerate(data):\n",
    "                for _ in range(pos):\n",
    "                    pos_x = i\n",
    "                    while pos_x == i:\n",
    "                        pos_x = random.randrange(0, len(data))\n",
    "                    self.indices.append((u, i, u, pos_x))\n",
    "                    self.target.append(1.0)\n",
    "                for _ in range(neg):\n",
    "                    neg_u = u\n",
    "                    while neg_u == u or len(records[neg_u]) == 0:\n",
    "                        neg_u = random.randrange(0, len(records))\n",
    "                    neg_x = random.randrange(0, len(records[neg_u]))\n",
    "                    self.indices.append((u, i, neg_u, neg_x))\n",
    "                    self.target.append(0.0)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        u, x, neg_u, neg_x = self.indices[index]\n",
    "        return (self.data[u][x], self.data[neg_u][neg_x]), self.target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/tark/.local/share/apps/anaconda3/lib/python3.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "1it [00:06,  6.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-498e6e3fe2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-26364b8923e3>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mNUM_FRAMES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5c6476af7f01>\u001b[0m in \u001b[0;36mextract_mfcc\u001b[0;34m(sound, sampling_rate, shift, L, mel_coefs, mfcc_coefs, alpha, eps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmfcc_coefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmfcc_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/apps/anaconda3/lib/python3.7/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/apps/anaconda3/lib/python3.7/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, power, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Build a Mel filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/apps/anaconda3/lib/python3.7/site-packages/librosa/filters.py\u001b[0m in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# lower and upper slopes for all bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_raw, test_raw = get_data()\n",
    "train_data = Records(train_raw)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "test_data = Records(test_raw)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size=INPUT_SIZE, num_layers=NUM_LAYERS, lstm_units=128):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=lstm_units, num_layers=num_layers)\n",
    "        self.sim = nn.Linear(in_features=1, out_features=1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # x, y -- tensors of size (batch, frames, 39)\n",
    "        x_h, _= self.lstm(x.transpose(0, 1))\n",
    "        y_h, _= self.lstm(y.transpose(0, 1))\n",
    "        \n",
    "        x_emb = x_h[-1]\n",
    "        y_emb = y_h[-1]\n",
    "        \n",
    "        sim = self.sim(nn.functional.cosine_similarity(x_emb, y_emb).unsqueeze(1)).squeeze(1)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, test_loader, device, n_epochs=N_EPOCHS, log_dir='./logs'):\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        k = 0\n",
    "        \n",
    "        for i, (records, labels) in enumerate(train_loader):\n",
    "            records_a, records_b = records\n",
    "            records_a = records_a.to(device)\n",
    "            records_b = records_b.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            outputs = model(records_a, records_b)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "            k += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= k\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        k = 0\n",
    "        for i, (records, labels) in enumerate(test_loader):\n",
    "            records_a, records_b = records\n",
    "            records_a = records_a.to(device)\n",
    "            records_b = records_b.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(records_a, records_b)\n",
    "                loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            k += 1\n",
    "        test_loss /= k\n",
    "        \n",
    "        writer.add_scalar('simple/train', train_loss, epoch)\n",
    "        writer.add_scalar('simple/test', test_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time train(model, optimizer, criterion, train_loader, test_loader, device, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
